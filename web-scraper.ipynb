{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a6e0c40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "from time import sleep\n",
    "\n",
    "# Install the webdriver_manager pip package in the current Jupyter kernel\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d31d584f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 98.0.4758\n",
      "Get LATEST chromedriver version for 98.0.4758 google-chrome\n",
      "Driver [/Users/matt/.wdm/drivers/chromedriver/mac64/98.0.4758.102/chromedriver] found in cache\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(ChromeDriverManager().install())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1e669d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_kayak(city_from, city_to, date_start, date_end):\n",
    "    \"\"\"City codes - it's the IATA codes!\n",
    "    Date format -  YYYY-MM-DD\"\"\"\n",
    "    \n",
    "    # Starting kayak chrome \n",
    "    kayak = ('https://www.kayak.co.uk/flights/' + city_from + '-' + city_to +\n",
    "             '/' + date_start + date_end + 'sort=bestflight_a?sort=price_a')\n",
    "    driver.get(kayak)\n",
    "    sleep(5) # sleep to allow the website to load\n",
    "    \n",
    "    # If the privacy modal opens, click accept\n",
    "    try:\n",
    "        accept_button_xpath = '//button[contains(@id, \"-accept\")]'\n",
    "        accept_button = driver.find_element(By.XPATH, accept_button_xpath)\n",
    "        accept_button.click()\n",
    "        sleep(1)\n",
    "    except Exception as e:\n",
    "        # try clicking accept all on the other flavour of privacy modal\n",
    "        # try:\n",
    "        print(e)\n",
    "        \n",
    "    actions = ActionChains(driver)\n",
    "    \n",
    "    # Click on filter to include flights only\n",
    "#     try: \n",
    "#         plane_checkbox_xpath = '//div[contains(@id, \"-transportation_plane-check-icon\")]'\n",
    "#         plane_only_xpath = '//button[contains(@id, \"-transportation_plane-only\")]'\n",
    "#         plane_checkbox_div = driver.find_element(By.XPATH, plane_checkbox_xpath)\n",
    "#         plane_only_button = driver.find_element(By.XPATH, plane_only_xpath)\n",
    "        \n",
    "#         actions.move_to_element(plane_checkbox_div)\n",
    "#         actions.pause(3)\n",
    "#         actions.click(plane_only_button)\n",
    "#         actions.perform()\n",
    "#         sleep(1)\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "abb68549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to obtain each property of a dictionary which will then be the exported csv file\n",
    "\n",
    "\"\"\"\n",
    "{\n",
    "origin: char(3)\n",
    "destination: char(3)\n",
    "time_start: int\n",
    "time_end: int\n",
    "date_start: date\n",
    "date_end: date\n",
    "price: int\n",
    "href: string;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# need to find a way to scrape a single flight, then iterate\n",
    "\n",
    "def scrape_hrefs():\n",
    "    \"\"\"\n",
    "    scrape the hrefs on the page\n",
    "    \"\"\"\n",
    "#     href_xpath = '//span[contains(text(), \"View Deal\")]//parent::a[@class=\"booking-link \"]' \n",
    "    href_xpath = '//a[contains(@aria-label, \"View Deal:\")]//span[@class=\"price-text\"]//ancestor::a[contains(@aria-label, \"View Deal:\")]'\n",
    "    anchors = driver.find_elements(By.XPATH, href_xpath)\n",
    "    \n",
    "    def get_href(anchor):\n",
    "        return anchor.get_attribute(\"href\")\n",
    "    \n",
    "    print(len(anchors))\n",
    "    \n",
    "    return list(map(get_href, anchors)) \n",
    "\n",
    "def scrape_prices(): \n",
    "    \"\"\"\n",
    "    scrape the prices on the page\n",
    "    \"\"\"\n",
    "    \n",
    "    price_xpath = '//a[contains(@aria-label, \"View Deal:\")]//span[@class=\"price-text\"]'\n",
    "    spans = driver.find_elements(By.XPATH, price_xpath)\n",
    "    \n",
    "    def get_price(span):\n",
    "        return span.text;\n",
    "    \n",
    "    print(len(spans))\n",
    "    \n",
    "    return list(map(get_price, spans))\n",
    "\n",
    "def scrape_start_times():\n",
    "    \"\"\"\n",
    "    scrape the depart times\n",
    "    \"\"\"\n",
    "    \n",
    "    start_times_xpath = '//a[contains(@aria-label, \"View Deal:\")]//preceding::div[@class=\"section stacked-carriers with-date\"]//following-sibling::div[@class=\"section times\"]//descendant::span[@class=\"depart-time base-time\"]'\n",
    "    spans = driver.find_elements(By.XPATH, start_times_xpath)\n",
    "    \n",
    "    def get_time(span):\n",
    "        return span.text\n",
    "    \n",
    "    print(len(spans))\n",
    "    \n",
    "    return list(map(get_time, spans))\n",
    "\n",
    "def scrape_end_times():\n",
    "    \"\"\"\n",
    "    scrape the depart times\n",
    "    \"\"\"\n",
    "    \n",
    "    start_times_xpath = '//a[contains(@aria-label, \"View Deal:\")]//preceding::div[@class=\"section stacked-carriers\"]//following-sibling::div[@class=\"section times\"]//descendant::span[@class=\"arrival-time base-time\"]'\n",
    "    spans = driver.find_elements(By.XPATH, start_times_xpath)\n",
    "    \n",
    "    def get_time(span):\n",
    "        return span.text\n",
    "    \n",
    "    print(len(spans))\n",
    "    \n",
    "    return list(map(get_time, spans))\n",
    "\n",
    "def scrape_date_start():\n",
    "    \"\"\"\n",
    "    scrape date of departure and date of return\n",
    "    \"\"\"\n",
    "    dates_xpath = '//a[contains(@aria-label, \"View Deal:\")]//preceding::div[@class=\"section stacked-carriers\"]//div[@class=\"bottom\"]//child::span'\n",
    "    spans = driver.find_elements(By.XPATH, dates_xpath)\n",
    "    \n",
    "    def get_date(span):\n",
    "        return span.text\n",
    "    \n",
    "    print(len(spans))\n",
    "    \n",
    "    return list(map(get_date, spans))\n",
    "\n",
    "def scrape_airports():\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f90c798d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//button[contains(@id, \"-accept\")]\"}\n",
      "  (Session info: chrome=98.0.4758.102)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_kayak(\"LGW\", \"CDG\", \"2022-03-15\", \"2022-03-22\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1b1c259e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[]\n",
      "5\n",
      "['21:23', '16:05', '10:30', '08:35', '22:10']\n"
     ]
    }
   ],
   "source": [
    "# print(scrape_hrefs())\n",
    "# print(scrape_prices())\n",
    "print(scrape_start_times())\n",
    "print(scrape_end_times())\n",
    "# print(scrape_date_start())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
